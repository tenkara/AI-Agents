{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92abfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: openai in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install requests python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d1db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GitHub client initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file in parent directory\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))\n",
    "\n",
    "def get_token():\n",
    "    \"\"\"Get GitHub token from environment.\"\"\"\n",
    "    return os.environ.get(\"GH_TOKEN\") or os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "class GitHubClient:\n",
    "    \"\"\"GitHub API client - connects to the remote GitHub API.\"\"\"\n",
    "    \n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.base = \"https://api.github.com\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3+json\",\n",
    "            \"User-Agent\": \"github-repos-summarizer\",\n",
    "            \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "        }\n",
    "\n",
    "    def list_user_repos(self, per_page=100):\n",
    "        \"\"\"List all repositories for the authenticated user.\"\"\"\n",
    "        url = f\"{self.base}/user/repos\"\n",
    "        params = {\"per_page\": per_page, \"sort\": \"updated\", \"direction\": \"desc\"}\n",
    "        repos = []\n",
    "        \n",
    "        while url:\n",
    "            resp = requests.get(url, headers=self.headers, params=params)\n",
    "            if resp.status_code == 401:\n",
    "                raise Exception(\"‚ùå Unauthorized: Check your GH_TOKEN\")\n",
    "            resp.raise_for_status()\n",
    "            repos.extend(resp.json())\n",
    "            \n",
    "            url = None\n",
    "            for part in resp.headers.get(\"Link\", \"\").split(\",\"):\n",
    "                if 'rel=\"next\"' in part:\n",
    "                    url = part.split(\";\")[0].strip().strip(\"<>\")\n",
    "                    break\n",
    "            params = None\n",
    "        return repos\n",
    "\n",
    "    def get_repo_details(self, owner, repo):\n",
    "        \"\"\"Get detailed repository information.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_repo_contents(self, owner, repo, path=\"\"):\n",
    "        \"\"\"Get contents of a repository path.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/contents/{path}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        if resp.status_code == 404:\n",
    "            return []\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_file_content(self, owner, repo, path):\n",
    "        \"\"\"Get decoded content of a specific file.\"\"\"\n",
    "        import base64\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/contents/{path}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        if resp.status_code == 404:\n",
    "            return None\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        if data.get(\"encoding\") == \"base64\":\n",
    "            return base64.b64decode(data[\"content\"]).decode(\"utf-8\", errors=\"ignore\")\n",
    "        return data.get(\"content\", \"\")\n",
    "\n",
    "    def get_repo_languages(self, owner, repo):\n",
    "        \"\"\"Get languages used in the repository.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/languages\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_repo_tree(self, owner, repo, sha=\"HEAD\", recursive=True):\n",
    "        \"\"\"Get the full file tree of a repository.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/git/trees/{sha}\"\n",
    "        params = {\"recursive\": \"1\"} if recursive else {}\n",
    "        resp = requests.get(url, headers=self.headers, params=params)\n",
    "        if resp.status_code == 404:\n",
    "            return {\"tree\": []}\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "# Initialize client\n",
    "token = get_token()\n",
    "if not token:\n",
    "    print(\"‚ùå No GitHub token found! Set GH_TOKEN in .env file.\")\n",
    "    github = None\n",
    "else:\n",
    "    github = GitHubClient(token)\n",
    "    print(\"‚úÖ GitHub client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e6316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Your GitHub Repositories (33 total):\n",
      "\n",
      "#    Name                                Language     ‚≠ê     Updated\n",
      "===========================================================================\n",
      "1    AI-Agents                           Jupyter Not  0     2025-11-30\n",
      "2    solidityHomeworks                   TypeScript   6     2024-01-12\n",
      "3    MapData                             Jupyter Not  0     2024-01-06\n",
      "4    langchain                           Jupyter Not  0     2023-11-14\n",
      "5    HF-Audio                            Jupyter Not  0     2023-07-09\n",
      "6    HF-DeepRL                           Jupyter Not  0     2023-07-02\n",
      "7    fastai-dl                           Jupyter Not  0     2023-06-30\n",
      "8    hf-nlp                              Jupyter Not  0     2023-05-30\n",
      "9    nlp-transformers                    Jupyter Not  0     2023-05-15\n",
      "10   openai-bc                           Jupyter Not  0     2023-05-09\n",
      "11   nn-bc                               Jupyter Not  0     2023-04-22\n",
      "12   dsml-bc                             Jupyter Not  0     2023-04-05\n",
      "13   springmast                          Java         0     2023-03-23\n",
      "14   ethdenver2023-hackathon             TypeScript   2     2023-03-11\n",
      "15   openai-stackhack-2023               Jupyter Not  1     2023-03-11\n",
      "16   pymast                              CSS          0     2023-02-11\n",
      "17   my-openai-playground                JavaScript   0     2023-01-24\n",
      "18   azure-ml-1                          Jupyter Not  0     2023-01-13\n",
      "19   simple-dapp-tutorial                JavaScript   0     2023-01-06\n",
      "20   figma-creations                     ‚Äî            0     2023-01-04\n",
      "21   openai-quickstart-node              JavaScript   0     2023-01-02\n",
      "22   ms-azure-databricks                 Python       0     2022-12-28\n",
      "23   tenkara.github.io                   ‚Äî            0     2022-12-11\n",
      "24   ethDenver-solidity-bootcamp         Solidity     0     2022-11-17\n",
      "25   treeNFT                             JavaScript   0     2022-02-18\n",
      "26   EthDenver2022Bounties               ‚Äî            0     2022-02-14\n",
      "27   dShop                               ‚Äî            0     2022-02-13\n",
      "28   blockchain                          JavaScript   0     2022-02-01\n",
      "29   tenkara                             ‚Äî            0     2022-02-01\n",
      "30   Machine-learning                    Python       0     2022-02-01\n",
      "31   demo-from-sf-repo                   ‚Äî            0     2022-01-26\n",
      "32   demo-repo                           HTML         0     2022-01-26\n",
      "33   go-go-squeeze                       Go           0     2018-02-04\n",
      "\n",
      "===========================================================================\n",
      "üìù Enter the number of the repo you want to analyze in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: List repositories and select one\n",
    "if github:\n",
    "    repos = github.list_user_repos()\n",
    "    \n",
    "    print(f\"üì¶ Your GitHub Repositories ({len(repos)} total):\\n\")\n",
    "    print(f\"{'#':<4} {'Name':<35} {'Language':<12} {'‚≠ê':<5} {'Updated'}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    for i, r in enumerate(repos, 1):\n",
    "        name = r.get(\"name\", \"\")[:34]\n",
    "        lang = (r.get(\"language\") or \"‚Äî\")[:11]\n",
    "        stars = r.get(\"stargazers_count\", 0)\n",
    "        updated = r.get(\"updated_at\", \"\")[:10]\n",
    "        print(f\"{i:<4} {name:<35} {lang:<12} {stars:<5} {updated}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"üìù Enter the number of the repo you want to analyze in the next cell.\")\n",
    "    \n",
    "    # Store repos for later use\n",
    "    repo_list = repos\n",
    "else:\n",
    "    repo_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f5c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Enter the repo number to analyze\n",
    "# ‚¨áÔ∏è CHANGE THIS NUMBER to select which repo to analyze ‚¨áÔ∏è\n",
    "SELECTED_REPO_NUMBER = 15  # this is the repo for openai-stackhack-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d046772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing repository: tenkara/openai-stackhack-2023\n",
      "\n",
      "======================================================================\n",
      "üìã Fetching repository details...\n",
      "üíª Analyzing languages/tech stack...\n",
      "üíª Analyzing languages/tech stack...\n",
      "üìÇ Mapping repository structure...\n",
      "üìÇ Mapping repository structure...\n",
      "üìÑ Reading key configuration files...\n",
      "\n",
      "‚úÖ Analysis complete!\n",
      "\n",
      "======================================================================\n",
      "üì¶ REPOSITORY OVERVIEW\n",
      "======================================================================\n",
      "Name:        tenkara/openai-stackhack-2023\n",
      "Description: No description\n",
      "URL:         https://github.com/tenkara/openai-stackhack-2023\n",
      "Created:     2023-02-25\n",
      "Updated:     2023-03-11\n",
      "Stars:       1 ‚≠ê\n",
      "Forks:       0\n",
      "Open Issues: 0\n",
      "Default Branch: main\n",
      "\n",
      "======================================================================\n",
      "üíª TECH STACK & LANGUAGES\n",
      "======================================================================\n",
      "Jupyter Notebook ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë  97.7%\n",
      "TypeScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.1%\n",
      "Python          ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.0%\n",
      "JavaScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.1%\n",
      "Dockerfile      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "Shell           ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "CSS             ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "\n",
      "üìö Detected Frameworks/Tools:\n",
      "  No specific frameworks detected\n",
      "\n",
      "======================================================================\n",
      "üèóÔ∏è ARCHITECTURE & STRUCTURE\n",
      "======================================================================\n",
      "Total files: 73\n",
      "Total directories: 5\n",
      "\n",
      "üìÅ Top-level structure:\n",
      "  üìÇ blockchain/ (2 items)\n",
      "  üìÇ client/ (55 items)\n",
      "  üìÇ playground/ (13 items)\n",
      "  üìÇ scraper/ (5 items)\n",
      "  üìÇ server/ (15 items)\n",
      "  üìÑ .gitignore\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è FUNCTIONALITY & PURPOSE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìÑ Reading key configuration files...\n",
      "\n",
      "‚úÖ Analysis complete!\n",
      "\n",
      "======================================================================\n",
      "üì¶ REPOSITORY OVERVIEW\n",
      "======================================================================\n",
      "Name:        tenkara/openai-stackhack-2023\n",
      "Description: No description\n",
      "URL:         https://github.com/tenkara/openai-stackhack-2023\n",
      "Created:     2023-02-25\n",
      "Updated:     2023-03-11\n",
      "Stars:       1 ‚≠ê\n",
      "Forks:       0\n",
      "Open Issues: 0\n",
      "Default Branch: main\n",
      "\n",
      "======================================================================\n",
      "üíª TECH STACK & LANGUAGES\n",
      "======================================================================\n",
      "Jupyter Notebook ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë  97.7%\n",
      "TypeScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.1%\n",
      "Python          ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.0%\n",
      "JavaScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.1%\n",
      "Dockerfile      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "Shell           ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "CSS             ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "\n",
      "üìö Detected Frameworks/Tools:\n",
      "  No specific frameworks detected\n",
      "\n",
      "======================================================================\n",
      "üèóÔ∏è ARCHITECTURE & STRUCTURE\n",
      "======================================================================\n",
      "Total files: 73\n",
      "Total directories: 5\n",
      "\n",
      "üìÅ Top-level structure:\n",
      "  üìÇ blockchain/ (2 items)\n",
      "  üìÇ client/ (55 items)\n",
      "  üìÇ playground/ (13 items)\n",
      "  üìÇ scraper/ (5 items)\n",
      "  üìÇ server/ (15 items)\n",
      "  üìÑ .gitignore\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è FUNCTIONALITY & PURPOSE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Analyze the selected repository\n",
    "class RepoAnalyzer:\n",
    "    \"\"\"Agent that analyzes a GitHub repository and provides detailed summaries.\"\"\"\n",
    "    \n",
    "    def __init__(self, github_client):\n",
    "        self.github = github_client\n",
    "        self.analysis = {}\n",
    "    \n",
    "    def analyze(self, owner, repo_name):\n",
    "        \"\"\"Perform full analysis of a repository.\"\"\"\n",
    "        print(f\"üîç Analyzing repository: {owner}/{repo_name}\\n\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # 1. Get repo details\n",
    "        print(\"üìã Fetching repository details...\")\n",
    "        details = self.github.get_repo_details(owner, repo_name)\n",
    "        self.analysis[\"details\"] = details\n",
    "        \n",
    "        # 2. Get languages\n",
    "        print(\"üíª Analyzing languages/tech stack...\")\n",
    "        languages = self.github.get_repo_languages(owner, repo_name)\n",
    "        self.analysis[\"languages\"] = languages\n",
    "        \n",
    "        # 3. Get file tree\n",
    "        print(\"üìÇ Mapping repository structure...\")\n",
    "        tree = self.github.get_repo_tree(owner, repo_name)\n",
    "        self.analysis[\"tree\"] = tree\n",
    "        \n",
    "        # 4. Get key files\n",
    "        print(\"üìÑ Reading key configuration files...\")\n",
    "        key_files = self._get_key_files(owner, repo_name, tree)\n",
    "        self.analysis[\"key_files\"] = key_files\n",
    "        \n",
    "        print(\"\\n‚úÖ Analysis complete!\\n\")\n",
    "        return self.analysis\n",
    "    \n",
    "    def _get_key_files(self, owner, repo, tree):\n",
    "        \"\"\"Read important files that reveal tech stack and architecture.\"\"\"\n",
    "        key_file_patterns = [\n",
    "            \"README.md\", \"readme.md\", \"README.MD\",\n",
    "            \"package.json\", \"requirements.txt\", \"Pipfile\", \"pyproject.toml\",\n",
    "            \"Cargo.toml\", \"go.mod\", \"pom.xml\", \"build.gradle\",\n",
    "            \"Dockerfile\", \"docker-compose.yml\", \"docker-compose.yaml\",\n",
    "            \"tsconfig.json\", \"hardhat.config.ts\", \"hardhat.config.js\",\n",
    "            \"foundry.toml\", \"truffle-config.js\",\n",
    "            \".env.example\", \"Makefile\"\n",
    "        ]\n",
    "        \n",
    "        files_content = {}\n",
    "        tree_files = [f[\"path\"] for f in tree.get(\"tree\", []) if f[\"type\"] == \"blob\"]\n",
    "        \n",
    "        for pattern in key_file_patterns:\n",
    "            if pattern in tree_files:\n",
    "                content = self.github.get_file_content(owner, repo, pattern)\n",
    "                if content:\n",
    "                    # Truncate large files\n",
    "                    files_content[pattern] = content[:5000] if len(content) > 5000 else content\n",
    "        \n",
    "        return files_content\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print a formatted summary of the analysis.\"\"\"\n",
    "        details = self.analysis.get(\"details\", {})\n",
    "        languages = self.analysis.get(\"languages\", {})\n",
    "        tree = self.analysis.get(\"tree\", {})\n",
    "        key_files = self.analysis.get(\"key_files\", {})\n",
    "        \n",
    "        # === BASIC INFO ===\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üì¶ REPOSITORY OVERVIEW\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Name:        {details.get('full_name', 'N/A')}\")\n",
    "        print(f\"Description: {details.get('description') or 'No description'}\")\n",
    "        print(f\"URL:         {details.get('html_url', 'N/A')}\")\n",
    "        print(f\"Created:     {details.get('created_at', '')[:10]}\")\n",
    "        print(f\"Updated:     {details.get('updated_at', '')[:10]}\")\n",
    "        print(f\"Stars:       {details.get('stargazers_count', 0)} ‚≠ê\")\n",
    "        print(f\"Forks:       {details.get('forks_count', 0)}\")\n",
    "        print(f\"Open Issues: {details.get('open_issues_count', 0)}\")\n",
    "        print(f\"Default Branch: {details.get('default_branch', 'main')}\")\n",
    "        \n",
    "        # === TECH STACK ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üíª TECH STACK & LANGUAGES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if languages:\n",
    "            total_bytes = sum(languages.values())\n",
    "            for lang, bytes_count in sorted(languages.items(), key=lambda x: -x[1]):\n",
    "                pct = (bytes_count / total_bytes) * 100\n",
    "                bar = \"‚ñà\" * int(pct / 5) + \"‚ñë\" * (20 - int(pct / 5))\n",
    "                print(f\"{lang:<15} {bar} {pct:>5.1f}%\")\n",
    "        else:\n",
    "            print(\"No language data available\")\n",
    "        \n",
    "        # Detect frameworks from key files\n",
    "        print(\"\\nüìö Detected Frameworks/Tools:\")\n",
    "        frameworks = self._detect_frameworks(key_files)\n",
    "        if frameworks:\n",
    "            for fw in frameworks:\n",
    "                print(f\"  ‚Ä¢ {fw}\")\n",
    "        else:\n",
    "            print(\"  No specific frameworks detected\")\n",
    "        \n",
    "        # === ARCHITECTURE ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üèóÔ∏è ARCHITECTURE & STRUCTURE\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        tree_items = tree.get(\"tree\", [])\n",
    "        dirs = sorted(set(f[\"path\"].split(\"/\")[0] for f in tree_items if \"/\" in f[\"path\"]))\n",
    "        files_root = [f[\"path\"] for f in tree_items if \"/\" not in f[\"path\"] and f[\"type\"] == \"blob\"]\n",
    "        \n",
    "        print(f\"Total files: {len([f for f in tree_items if f['type'] == 'blob'])}\")\n",
    "        print(f\"Total directories: {len(dirs)}\")\n",
    "        \n",
    "        print(\"\\nüìÅ Top-level structure:\")\n",
    "        for d in dirs[:15]:\n",
    "            subfiles = len([f for f in tree_items if f[\"path\"].startswith(d + \"/\")])\n",
    "            print(f\"  üìÇ {d}/ ({subfiles} items)\")\n",
    "        if len(dirs) > 15:\n",
    "            print(f\"  ... and {len(dirs) - 15} more directories\")\n",
    "        \n",
    "        for f in files_root[:10]:\n",
    "            print(f\"  üìÑ {f}\")\n",
    "        \n",
    "        # === FUNCTIONALITY ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"‚öôÔ∏è FUNCTIONALITY & PURPOSE\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Print README excerpt if available\n",
    "        readme_content = key_files.get(\"README.md\") or key_files.get(\"readme.md\") or key_files.get(\"README.MD\")\n",
    "        if readme_content:\n",
    "            print(\"\\nüìñ From README:\")\n",
    "            # Get first meaningful section (skip badges/images)\n",
    "            lines = readme_content.split(\"\\n\")\n",
    "            meaningful_lines = []\n",
    "            for line in lines[:50]:\n",
    "                if line.strip() and not line.startswith(\"![\") and not line.startswith(\"<img\"):\n",
    "                    meaningful_lines.append(line)\n",
    "                if len(meaningful_lines) >= 15:\n",
    "                    break\n",
    "            print(\"\\n\".join(meaningful_lines[:15]))\n",
    "            if len(meaningful_lines) > 15:\n",
    "                print(\"...\")\n",
    "        \n",
    "        # Print dependencies\n",
    "        if \"package.json\" in key_files:\n",
    "            print(\"\\nüì¶ NPM Dependencies (from package.json):\")\n",
    "            self._print_npm_deps(key_files[\"package.json\"])\n",
    "        \n",
    "        if \"requirements.txt\" in key_files:\n",
    "            print(\"\\nüêç Python Dependencies (from requirements.txt):\")\n",
    "            deps = [line.strip() for line in key_files[\"requirements.txt\"].split(\"\\n\") \n",
    "                    if line.strip() and not line.startswith(\"#\")][:10]\n",
    "            for dep in deps:\n",
    "                print(f\"  ‚Ä¢ {dep}\")\n",
    "            if len(deps) > 10:\n",
    "                print(f\"  ... and more\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    def _detect_frameworks(self, key_files):\n",
    "        \"\"\"Detect frameworks based on config files.\"\"\"\n",
    "        frameworks = []\n",
    "        \n",
    "        if \"package.json\" in key_files:\n",
    "            pkg = key_files[\"package.json\"]\n",
    "            if \"react\" in pkg.lower(): frameworks.append(\"React\")\n",
    "            if \"next\" in pkg.lower(): frameworks.append(\"Next.js\")\n",
    "            if \"vue\" in pkg.lower(): frameworks.append(\"Vue.js\")\n",
    "            if \"angular\" in pkg.lower(): frameworks.append(\"Angular\")\n",
    "            if \"express\" in pkg.lower(): frameworks.append(\"Express.js\")\n",
    "            if \"hardhat\" in pkg.lower(): frameworks.append(\"Hardhat (Ethereum)\")\n",
    "            if \"ethers\" in pkg.lower(): frameworks.append(\"Ethers.js\")\n",
    "            if \"web3\" in pkg.lower(): frameworks.append(\"Web3.js\")\n",
    "            if \"typescript\" in pkg.lower(): frameworks.append(\"TypeScript\")\n",
    "        \n",
    "        if \"requirements.txt\" in key_files or \"pyproject.toml\" in key_files:\n",
    "            content = key_files.get(\"requirements.txt\", \"\") + key_files.get(\"pyproject.toml\", \"\")\n",
    "            if \"django\" in content.lower(): frameworks.append(\"Django\")\n",
    "            if \"flask\" in content.lower(): frameworks.append(\"Flask\")\n",
    "            if \"fastapi\" in content.lower(): frameworks.append(\"FastAPI\")\n",
    "            if \"torch\" in content.lower(): frameworks.append(\"PyTorch\")\n",
    "            if \"tensorflow\" in content.lower(): frameworks.append(\"TensorFlow\")\n",
    "            if \"langchain\" in content.lower(): frameworks.append(\"LangChain\")\n",
    "            if \"openai\" in content.lower(): frameworks.append(\"OpenAI API\")\n",
    "        \n",
    "        if \"hardhat.config.ts\" in key_files or \"hardhat.config.js\" in key_files:\n",
    "            frameworks.append(\"Hardhat (Solidity)\")\n",
    "        if \"foundry.toml\" in key_files:\n",
    "            frameworks.append(\"Foundry (Solidity)\")\n",
    "        if \"truffle-config.js\" in key_files:\n",
    "            frameworks.append(\"Truffle (Solidity)\")\n",
    "        if \"Dockerfile\" in key_files:\n",
    "            frameworks.append(\"Docker\")\n",
    "        if \"docker-compose.yml\" in key_files or \"docker-compose.yaml\" in key_files:\n",
    "            frameworks.append(\"Docker Compose\")\n",
    "        \n",
    "        return list(set(frameworks))\n",
    "    \n",
    "    def _print_npm_deps(self, package_json_content):\n",
    "        \"\"\"Parse and print NPM dependencies.\"\"\"\n",
    "        import json\n",
    "        try:\n",
    "            pkg = json.loads(package_json_content)\n",
    "            deps = list(pkg.get(\"dependencies\", {}).keys())[:8]\n",
    "            dev_deps = list(pkg.get(\"devDependencies\", {}).keys())[:5]\n",
    "            \n",
    "            if deps:\n",
    "                print(\"  Dependencies:\")\n",
    "                for d in deps:\n",
    "                    print(f\"    ‚Ä¢ {d}\")\n",
    "                if len(pkg.get(\"dependencies\", {})) > 8:\n",
    "                    print(f\"    ... and {len(pkg.get('dependencies', {})) - 8} more\")\n",
    "            \n",
    "            if dev_deps:\n",
    "                print(\"  Dev Dependencies:\")\n",
    "                for d in dev_deps:\n",
    "                    print(f\"    ‚Ä¢ {d}\")\n",
    "        except:\n",
    "            print(\"  (Could not parse package.json)\")\n",
    "\n",
    "# Run the analysis\n",
    "if github and repo_list:\n",
    "    idx = SELECTED_REPO_NUMBER - 1\n",
    "    if 0 <= idx < len(repo_list):\n",
    "        selected = repo_list[idx]\n",
    "        owner = selected[\"owner\"][\"login\"]\n",
    "        repo_name = selected[\"name\"]\n",
    "        \n",
    "        analyzer = RepoAnalyzer(github)\n",
    "        analyzer.analyze(owner, repo_name)\n",
    "        analyzer.print_summary()\n",
    "    else:\n",
    "        print(f\"‚ùå Invalid selection. Choose a number between 1 and {len(repo_list)}\")\n",
    "else:\n",
    "    print(\"‚ùå Run the previous cells first to load repos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92abfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: openai in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\ai-agents\\3-mcp-myrepos-summary\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install requests python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d1db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GitHub client initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file in parent directory\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))\n",
    "\n",
    "def get_token():\n",
    "    \"\"\"Get GitHub token from environment.\"\"\"\n",
    "    return os.environ.get(\"GH_TOKEN\") or os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "class GitHubClient:\n",
    "    \"\"\"GitHub API client - connects to the remote GitHub API.\"\"\"\n",
    "    \n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.base = \"https://api.github.com\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Accept\": \"application/vnd.github.v3+json\",\n",
    "            \"User-Agent\": \"github-repos-summarizer\",\n",
    "            \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "        }\n",
    "\n",
    "    def list_user_repos(self, per_page=100):\n",
    "        \"\"\"List all repositories for the authenticated user.\"\"\"\n",
    "        url = f\"{self.base}/user/repos\"\n",
    "        params = {\"per_page\": per_page, \"sort\": \"updated\", \"direction\": \"desc\"}\n",
    "        repos = []\n",
    "        \n",
    "        while url:\n",
    "            resp = requests.get(url, headers=self.headers, params=params)\n",
    "            if resp.status_code == 401:\n",
    "                raise Exception(\"‚ùå Unauthorized: Check your GH_TOKEN\")\n",
    "            resp.raise_for_status()\n",
    "            repos.extend(resp.json())\n",
    "            \n",
    "            url = None\n",
    "            for part in resp.headers.get(\"Link\", \"\").split(\",\"):\n",
    "                if 'rel=\"next\"' in part:\n",
    "                    url = part.split(\";\")[0].strip().strip(\"<>\")\n",
    "                    break\n",
    "            params = None\n",
    "        return repos\n",
    "\n",
    "    def get_repo_details(self, owner, repo):\n",
    "        \"\"\"Get detailed repository information.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_repo_contents(self, owner, repo, path=\"\"):\n",
    "        \"\"\"Get contents of a repository path.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/contents/{path}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        if resp.status_code == 404:\n",
    "            return []\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_file_content(self, owner, repo, path):\n",
    "        \"\"\"Get decoded content of a specific file.\"\"\"\n",
    "        import base64\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/contents/{path}\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        if resp.status_code == 404:\n",
    "            return None\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        if data.get(\"encoding\") == \"base64\":\n",
    "            return base64.b64decode(data[\"content\"]).decode(\"utf-8\", errors=\"ignore\")\n",
    "        return data.get(\"content\", \"\")\n",
    "\n",
    "    def get_repo_languages(self, owner, repo):\n",
    "        \"\"\"Get languages used in the repository.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/languages\"\n",
    "        resp = requests.get(url, headers=self.headers)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "    def get_repo_tree(self, owner, repo, sha=\"HEAD\", recursive=True):\n",
    "        \"\"\"Get the full file tree of a repository.\"\"\"\n",
    "        url = f\"{self.base}/repos/{owner}/{repo}/git/trees/{sha}\"\n",
    "        params = {\"recursive\": \"1\"} if recursive else {}\n",
    "        resp = requests.get(url, headers=self.headers, params=params)\n",
    "        if resp.status_code == 404:\n",
    "            return {\"tree\": []}\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "\n",
    "# Initialize client\n",
    "token = get_token()\n",
    "if not token:\n",
    "    print(\"‚ùå No GitHub token found! Set GH_TOKEN in .env file.\")\n",
    "    github = None\n",
    "else:\n",
    "    github = GitHubClient(token)\n",
    "    print(\"‚úÖ GitHub client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431e6316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Your GitHub Repositories (33 total):\n",
      "\n",
      "#    Name                                Language     ‚≠ê     Updated\n",
      "===========================================================================\n",
      "1    AI-Agents                           Jupyter Not  0     2025-11-30\n",
      "2    solidityHomeworks                   TypeScript   6     2024-01-12\n",
      "3    MapData                             Jupyter Not  0     2024-01-06\n",
      "4    langchain                           Jupyter Not  0     2023-11-14\n",
      "5    HF-Audio                            Jupyter Not  0     2023-07-09\n",
      "6    HF-DeepRL                           Jupyter Not  0     2023-07-02\n",
      "7    fastai-dl                           Jupyter Not  0     2023-06-30\n",
      "8    hf-nlp                              Jupyter Not  0     2023-05-30\n",
      "9    nlp-transformers                    Jupyter Not  0     2023-05-15\n",
      "10   openai-bc                           Jupyter Not  0     2023-05-09\n",
      "11   nn-bc                               Jupyter Not  0     2023-04-22\n",
      "12   dsml-bc                             Jupyter Not  0     2023-04-05\n",
      "13   springmast                          Java         0     2023-03-23\n",
      "14   ethdenver2023-hackathon             TypeScript   2     2023-03-11\n",
      "15   openai-stackhack-2023               Jupyter Not  1     2023-03-11\n",
      "16   pymast                              CSS          0     2023-02-11\n",
      "17   my-openai-playground                JavaScript   0     2023-01-24\n",
      "18   azure-ml-1                          Jupyter Not  0     2023-01-13\n",
      "19   simple-dapp-tutorial                JavaScript   0     2023-01-06\n",
      "20   figma-creations                     ‚Äî            0     2023-01-04\n",
      "21   openai-quickstart-node              JavaScript   0     2023-01-02\n",
      "22   ms-azure-databricks                 Python       0     2022-12-28\n",
      "23   tenkara.github.io                   ‚Äî            0     2022-12-11\n",
      "24   ethDenver-solidity-bootcamp         Solidity     0     2022-11-17\n",
      "25   treeNFT                             JavaScript   0     2022-02-18\n",
      "26   EthDenver2022Bounties               ‚Äî            0     2022-02-14\n",
      "27   dShop                               ‚Äî            0     2022-02-13\n",
      "28   blockchain                          JavaScript   0     2022-02-01\n",
      "29   tenkara                             ‚Äî            0     2022-02-01\n",
      "30   Machine-learning                    Python       0     2022-02-01\n",
      "31   demo-from-sf-repo                   ‚Äî            0     2022-01-26\n",
      "32   demo-repo                           HTML         0     2022-01-26\n",
      "33   go-go-squeeze                       Go           0     2018-02-04\n",
      "\n",
      "===========================================================================\n",
      "üìù Enter the number of the repo you want to analyze in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: List repositories and select one\n",
    "if github:\n",
    "    repos = github.list_user_repos()\n",
    "    \n",
    "    print(f\"üì¶ Your GitHub Repositories ({len(repos)} total):\\n\")\n",
    "    print(f\"{'#':<4} {'Name':<35} {'Language':<12} {'‚≠ê':<5} {'Updated'}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    for i, r in enumerate(repos, 1):\n",
    "        name = r.get(\"name\", \"\")[:34]\n",
    "        lang = (r.get(\"language\") or \"‚Äî\")[:11]\n",
    "        stars = r.get(\"stargazers_count\", 0)\n",
    "        updated = r.get(\"updated_at\", \"\")[:10]\n",
    "        print(f\"{i:<4} {name:<35} {lang:<12} {stars:<5} {updated}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"üìù Enter the number of the repo you want to analyze in the next cell.\")\n",
    "    \n",
    "    # Store repos for later use\n",
    "    repo_list = repos\n",
    "else:\n",
    "    repo_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f5c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Enter the repo number to analyze\n",
    "# ‚¨áÔ∏è CHANGE THIS NUMBER to select which repo to analyze ‚¨áÔ∏è\n",
    "SELECTED_REPO_NUMBER = 15  # this is the repo for openai-stackhack-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d046772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing repository: tenkara/openai-stackhack-2023\n",
      "\n",
      "======================================================================\n",
      "üìã Fetching repository details...\n",
      "üíª Analyzing languages/tech stack...\n",
      "üíª Analyzing languages/tech stack...\n",
      "üìÇ Mapping repository structure...\n",
      "üìÇ Mapping repository structure...\n",
      "üìÑ Reading configuration files...\n",
      "üî¨ Analyzing source code...\n",
      "üìÑ Reading configuration files...\n",
      "üî¨ Analyzing source code...\n",
      "üíº Inferring business functionality...\n",
      "\n",
      "‚úÖ Analysis complete!\n",
      "\n",
      "======================================================================\n",
      "üì¶ REPOSITORY OVERVIEW\n",
      "======================================================================\n",
      "Name:        tenkara/openai-stackhack-2023\n",
      "Description: No description\n",
      "URL:         https://github.com/tenkara/openai-stackhack-2023\n",
      "Created:     2023-02-25\n",
      "Updated:     2023-03-11\n",
      "Stars:       1 ‚≠ê  |  Forks: 0\n",
      "\n",
      "======================================================================\n",
      "üíº BUSINESS FUNCTIONALITY SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìù This is a General software project that implements various features.\n",
      "\n",
      "üë§ User-Facing Endpoints:\n",
      "   ‚Ä¢ Route: /public\n",
      "   ‚Ä¢ Route: /\n",
      "   ‚Ä¢ Route: /sp/chat\n",
      "   ‚Ä¢ Route: /private\n",
      "   ‚Ä¢ Route: /chat\n",
      "\n",
      "======================================================================\n",
      "üíª TECH STACK & LANGUAGES\n",
      "======================================================================\n",
      "Jupyter Notebook ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë  97.7%\n",
      "TypeScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.1%\n",
      "Python          ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.0%\n",
      "JavaScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.1%\n",
      "Dockerfile      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "Shell           ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "\n",
      "üìö Frameworks/Tools:\n",
      "   ‚Ä¢ No specific frameworks detected\n",
      "\n",
      "======================================================================\n",
      "üèóÔ∏è ARCHITECTURE & STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "üìä Source Files: python: 9, javascript: 4, typescript: 13, jupyter: 7\n",
      "\n",
      "üìÅ Structure (5 directories):\n",
      "   üìÇ blockchain/ (2 items)\n",
      "   üìÇ client/ (55 items)\n",
      "   üìÇ playground/ (13 items)\n",
      "   üìÇ scraper/ (5 items)\n",
      "   üìÇ server/ (15 items)\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è CODE MODULES & FUNCTIONS\n",
      "======================================================================\n",
      "\n",
      "üìÑ playground/main.py\n",
      "\n",
      "üìÑ server/server.py\n",
      "   Purpose: Load Environment Variables \n",
      "   Functions: public, chat, private, index, spchat\n",
      "   Routes: /public, /, /sp/chat, /private, /chat\n",
      "\n",
      "üìÑ playground/redis/aimd-chat-redis-demo.ipynb\n",
      "   Purpose: Notebook: aimd-chat-redis-demo.ipynb\n",
      "   Notebook: 14 code, 0 markdown cells\n",
      "\n",
      "üìÑ playground/redis/aimd-chat-test.ipynb\n",
      "   Purpose: Notebook: aimd-chat-test.ipynb\n",
      "   Notebook: 41 code, 0 markdown cells\n",
      "\n",
      "üìÑ playground/redis/mplus-chat-test.ipynb\n",
      "   Purpose: Notebook: mplus-chat-test.ipynb\n",
      "   Notebook: 32 code, 0 markdown cells\n",
      "\n",
      "======================================================================\n",
      "üìñ PROJECT DESCRIPTION (README)\n",
      "======================================================================\n",
      "\n",
      "No README found\n",
      "\n",
      "======================================================================\n",
      "üì¶ KEY DEPENDENCIES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üíº Inferring business functionality...\n",
      "\n",
      "‚úÖ Analysis complete!\n",
      "\n",
      "======================================================================\n",
      "üì¶ REPOSITORY OVERVIEW\n",
      "======================================================================\n",
      "Name:        tenkara/openai-stackhack-2023\n",
      "Description: No description\n",
      "URL:         https://github.com/tenkara/openai-stackhack-2023\n",
      "Created:     2023-02-25\n",
      "Updated:     2023-03-11\n",
      "Stars:       1 ‚≠ê  |  Forks: 0\n",
      "\n",
      "======================================================================\n",
      "üíº BUSINESS FUNCTIONALITY SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìù This is a General software project that implements various features.\n",
      "\n",
      "üë§ User-Facing Endpoints:\n",
      "   ‚Ä¢ Route: /public\n",
      "   ‚Ä¢ Route: /\n",
      "   ‚Ä¢ Route: /sp/chat\n",
      "   ‚Ä¢ Route: /private\n",
      "   ‚Ä¢ Route: /chat\n",
      "\n",
      "======================================================================\n",
      "üíª TECH STACK & LANGUAGES\n",
      "======================================================================\n",
      "Jupyter Notebook ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë  97.7%\n",
      "TypeScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.1%\n",
      "Python          ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   1.0%\n",
      "JavaScript      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.1%\n",
      "Dockerfile      ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "Shell           ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   0.0%\n",
      "\n",
      "üìö Frameworks/Tools:\n",
      "   ‚Ä¢ No specific frameworks detected\n",
      "\n",
      "======================================================================\n",
      "üèóÔ∏è ARCHITECTURE & STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "üìä Source Files: python: 9, javascript: 4, typescript: 13, jupyter: 7\n",
      "\n",
      "üìÅ Structure (5 directories):\n",
      "   üìÇ blockchain/ (2 items)\n",
      "   üìÇ client/ (55 items)\n",
      "   üìÇ playground/ (13 items)\n",
      "   üìÇ scraper/ (5 items)\n",
      "   üìÇ server/ (15 items)\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è CODE MODULES & FUNCTIONS\n",
      "======================================================================\n",
      "\n",
      "üìÑ playground/main.py\n",
      "\n",
      "üìÑ server/server.py\n",
      "   Purpose: Load Environment Variables \n",
      "   Functions: public, chat, private, index, spchat\n",
      "   Routes: /public, /, /sp/chat, /private, /chat\n",
      "\n",
      "üìÑ playground/redis/aimd-chat-redis-demo.ipynb\n",
      "   Purpose: Notebook: aimd-chat-redis-demo.ipynb\n",
      "   Notebook: 14 code, 0 markdown cells\n",
      "\n",
      "üìÑ playground/redis/aimd-chat-test.ipynb\n",
      "   Purpose: Notebook: aimd-chat-test.ipynb\n",
      "   Notebook: 41 code, 0 markdown cells\n",
      "\n",
      "üìÑ playground/redis/mplus-chat-test.ipynb\n",
      "   Purpose: Notebook: mplus-chat-test.ipynb\n",
      "   Notebook: 32 code, 0 markdown cells\n",
      "\n",
      "======================================================================\n",
      "üìñ PROJECT DESCRIPTION (README)\n",
      "======================================================================\n",
      "\n",
      "No README found\n",
      "\n",
      "======================================================================\n",
      "üì¶ KEY DEPENDENCIES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Analyze the selected repository\n",
    "import re\n",
    "import json\n",
    "\n",
    "class RepoAnalyzer:\n",
    "    \"\"\"Agent that analyzes a GitHub repository and provides detailed summaries.\"\"\"\n",
    "    \n",
    "    def __init__(self, github_client):\n",
    "        self.github = github_client\n",
    "        self.analysis = {}\n",
    "    \n",
    "    def analyze(self, owner, repo_name):\n",
    "        \"\"\"Perform full analysis of a repository.\"\"\"\n",
    "        print(f\"üîç Analyzing repository: {owner}/{repo_name}\\n\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # 1. Get repo details\n",
    "        print(\"üìã Fetching repository details...\")\n",
    "        details = self.github.get_repo_details(owner, repo_name)\n",
    "        self.analysis[\"details\"] = details\n",
    "        \n",
    "        # 2. Get languages\n",
    "        print(\"üíª Analyzing languages/tech stack...\")\n",
    "        languages = self.github.get_repo_languages(owner, repo_name)\n",
    "        self.analysis[\"languages\"] = languages\n",
    "        \n",
    "        # 3. Get file tree\n",
    "        print(\"üìÇ Mapping repository structure...\")\n",
    "        tree = self.github.get_repo_tree(owner, repo_name)\n",
    "        self.analysis[\"tree\"] = tree\n",
    "        \n",
    "        # 4. Get key config files\n",
    "        print(\"üìÑ Reading configuration files...\")\n",
    "        key_files = self._get_key_files(owner, repo_name, tree)\n",
    "        self.analysis[\"key_files\"] = key_files\n",
    "        \n",
    "        # 5. Analyze source code\n",
    "        print(\"üî¨ Analyzing source code...\")\n",
    "        code_analysis = self._analyze_source_code(owner, repo_name, tree)\n",
    "        self.analysis[\"code_analysis\"] = code_analysis\n",
    "        \n",
    "        # 6. Infer business functionality\n",
    "        print(\"üíº Inferring business functionality...\")\n",
    "        business_analysis = self._analyze_business_functionality(key_files, code_analysis, details)\n",
    "        self.analysis[\"business\"] = business_analysis\n",
    "        \n",
    "        print(\"\\n‚úÖ Analysis complete!\\n\")\n",
    "        return self.analysis\n",
    "    \n",
    "    def _get_key_files(self, owner, repo, tree):\n",
    "        \"\"\"Read important files that reveal tech stack and architecture.\"\"\"\n",
    "        key_file_patterns = [\n",
    "            \"README.md\", \"readme.md\", \"README.MD\",\n",
    "            \"package.json\", \"requirements.txt\", \"Pipfile\", \"pyproject.toml\",\n",
    "            \"Cargo.toml\", \"go.mod\", \"pom.xml\", \"build.gradle\",\n",
    "            \"Dockerfile\", \"docker-compose.yml\", \"docker-compose.yaml\",\n",
    "            \"tsconfig.json\", \"hardhat.config.ts\", \"hardhat.config.js\",\n",
    "            \"foundry.toml\", \"truffle-config.js\",\n",
    "            \".env.example\", \"Makefile\", \"AGENTS.md\", \"CONTRIBUTING.md\"\n",
    "        ]\n",
    "        \n",
    "        files_content = {}\n",
    "        tree_files = [f[\"path\"] for f in tree.get(\"tree\", []) if f[\"type\"] == \"blob\"]\n",
    "        \n",
    "        for pattern in key_file_patterns:\n",
    "            if pattern in tree_files:\n",
    "                content = self.github.get_file_content(owner, repo, pattern)\n",
    "                if content:\n",
    "                    files_content[pattern] = content[:8000] if len(content) > 8000 else content\n",
    "        \n",
    "        return files_content\n",
    "    \n",
    "    def _analyze_source_code(self, owner, repo, tree):\n",
    "        \"\"\"Analyze source code files to understand functionality.\"\"\"\n",
    "        tree_files = tree.get(\"tree\", [])\n",
    "        \n",
    "        # Categorize files by type\n",
    "        code_files = {\n",
    "            \"python\": [], \"javascript\": [], \"typescript\": [],\n",
    "            \"solidity\": [], \"jupyter\": [], \"other\": []\n",
    "        }\n",
    "        \n",
    "        for f in tree_files:\n",
    "            if f[\"type\"] != \"blob\":\n",
    "                continue\n",
    "            path = f[\"path\"]\n",
    "            if path.endswith(\".py\"): code_files[\"python\"].append(path)\n",
    "            elif path.endswith((\".js\", \".jsx\")): code_files[\"javascript\"].append(path)\n",
    "            elif path.endswith((\".ts\", \".tsx\")): code_files[\"typescript\"].append(path)\n",
    "            elif path.endswith(\".sol\"): code_files[\"solidity\"].append(path)\n",
    "            elif path.endswith(\".ipynb\"): code_files[\"jupyter\"].append(path)\n",
    "        \n",
    "        analysis = {\n",
    "            \"file_counts\": {k: len(v) for k, v in code_files.items()},\n",
    "            \"main_modules\": [],\n",
    "            \"contracts\": [],\n",
    "            \"all_functions\": [],\n",
    "            \"all_classes\": [],\n",
    "            \"all_routes\": []\n",
    "        }\n",
    "        \n",
    "        # Find priority files (entry points)\n",
    "        priority_files = []\n",
    "        for files in [code_files[\"python\"], code_files[\"javascript\"], code_files[\"typescript\"]]:\n",
    "            for f in files:\n",
    "                name = f.split(\"/\")[-1].lower()\n",
    "                if name in [\"main.py\", \"app.py\", \"index.py\", \"server.py\", \"__main__.py\",\n",
    "                           \"index.js\", \"index.ts\", \"app.js\", \"app.ts\", \"server.js\", \"server.ts\"]:\n",
    "                    priority_files.append(f)\n",
    "                elif any(x in name for x in [\"route\", \"api\", \"controller\", \"service\", \"model\", \"view\"]):\n",
    "                    priority_files.append(f)\n",
    "        \n",
    "        # Also check src/ and lib/ directories\n",
    "        for f in tree_files:\n",
    "            path = f[\"path\"]\n",
    "            if f[\"type\"] == \"blob\" and (path.startswith(\"src/\") or path.startswith(\"lib/\")):\n",
    "                if path.endswith((\".py\", \".js\", \".ts\", \".jsx\", \".tsx\")):\n",
    "                    if path not in priority_files:\n",
    "                        priority_files.append(path)\n",
    "        \n",
    "        # Analyze up to 12 key files\n",
    "        files_to_analyze = priority_files[:12]\n",
    "        if not files_to_analyze:\n",
    "            all_code = code_files[\"python\"] + code_files[\"javascript\"] + code_files[\"typescript\"]\n",
    "            files_to_analyze = [f for f in all_code if \"node_modules\" not in f and \"test\" not in f.lower()][:8]\n",
    "        \n",
    "        for file_path in files_to_analyze:\n",
    "            content = self.github.get_file_content(owner, repo, file_path)\n",
    "            if content:\n",
    "                file_analysis = self._analyze_file_content(file_path, content)\n",
    "                if file_analysis:\n",
    "                    analysis[\"main_modules\"].append({\"path\": file_path, \"analysis\": file_analysis})\n",
    "                    analysis[\"all_functions\"].extend(file_analysis.get(\"functions\", []))\n",
    "                    analysis[\"all_classes\"].extend(file_analysis.get(\"classes\", []))\n",
    "                    analysis[\"all_routes\"].extend(file_analysis.get(\"api_routes\", []))\n",
    "        \n",
    "        # Analyze Solidity contracts\n",
    "        for sol_file in code_files[\"solidity\"][:5]:\n",
    "            content = self.github.get_file_content(owner, repo, sol_file)\n",
    "            if content:\n",
    "                contracts = self._extract_solidity_info(content)\n",
    "                if contracts:\n",
    "                    analysis[\"contracts\"].extend(contracts)\n",
    "        \n",
    "        # Analyze Jupyter notebooks\n",
    "        for nb_file in code_files[\"jupyter\"][:3]:\n",
    "            content = self.github.get_file_content(owner, repo, nb_file)\n",
    "            if content:\n",
    "                nb_info = self._analyze_notebook(nb_file, content)\n",
    "                if nb_info:\n",
    "                    analysis[\"main_modules\"].append({\"path\": nb_file, \"analysis\": nb_info})\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_file_content(self, path, content):\n",
    "        \"\"\"Extract functions, classes, and purpose from a source file.\"\"\"\n",
    "        analysis = {\"purpose\": \"\", \"functions\": [], \"classes\": [], \"api_routes\": [], \"business_hints\": []}\n",
    "        lines = content.split(\"\\n\")\n",
    "        \n",
    "        # Extract top comment/docstring\n",
    "        for i, line in enumerate(lines[:25]):\n",
    "            if line.strip().startswith(\"#\") or line.strip().startswith(\"//\"):\n",
    "                analysis[\"purpose\"] += line.strip().lstrip(\"#/\").strip() + \" \"\n",
    "            elif '\"\"\"' in line or \"'''\" in line:\n",
    "                doc_lines = []\n",
    "                for dl in lines[i:i+15]:\n",
    "                    doc_lines.append(dl)\n",
    "                    if len(doc_lines) > 1 and ('\"\"\"' in dl or \"'''\" in dl):\n",
    "                        break\n",
    "                analysis[\"purpose\"] = \" \".join(doc_lines).replace('\"\"\"', '').replace(\"'''\", '').strip()\n",
    "                break\n",
    "        \n",
    "        # Python analysis\n",
    "        if path.endswith(\".py\"):\n",
    "            for match in re.finditer(r'def\\s+(\\w+)\\s*\\([^)]*\\)', content):\n",
    "                func_name = match.group(1)\n",
    "                if not func_name.startswith(\"_\") or func_name == \"__init__\":\n",
    "                    analysis[\"functions\"].append(func_name)\n",
    "            for match in re.finditer(r'class\\s+(\\w+)', content):\n",
    "                analysis[\"classes\"].append(match.group(1))\n",
    "            for match in re.finditer(r'@(?:app|router|api)\\.(?:get|post|put|delete|route)\\s*\\([\\'\"]([^\\'\"]+)', content, re.I):\n",
    "                analysis[\"api_routes\"].append(match.group(1))\n",
    "        \n",
    "        # JS/TS analysis\n",
    "        elif path.endswith((\".js\", \".ts\", \".jsx\", \".tsx\")):\n",
    "            for pattern in [r'function\\s+(\\w+)', r'const\\s+(\\w+)\\s*=\\s*(?:async\\s*)?\\([^)]*\\)\\s*=>']:\n",
    "                for match in re.finditer(pattern, content):\n",
    "                    analysis[\"functions\"].append(match.group(1))\n",
    "            for match in re.finditer(r'class\\s+(\\w+)', content):\n",
    "                analysis[\"classes\"].append(match.group(1))\n",
    "            for match in re.finditer(r'\\.(?:get|post|put|delete|patch)\\s*\\([\\'\"]([^\\'\"]+)', content):\n",
    "                analysis[\"api_routes\"].append(match.group(1))\n",
    "        \n",
    "        # Extract business-related keywords from function/class names\n",
    "        business_keywords = [\"user\", \"auth\", \"login\", \"payment\", \"order\", \"product\", \"cart\", \"checkout\",\n",
    "                          \"invoice\", \"customer\", \"account\", \"transaction\", \"wallet\", \"token\", \"mint\",\n",
    "                          \"transfer\", \"swap\", \"stake\", \"claim\", \"reward\", \"vote\", \"proposal\", \"dao\",\n",
    "                          \"nft\", \"marketplace\", \"auction\", \"bid\", \"listing\", \"subscription\", \"plan\"]\n",
    "        \n",
    "        all_names = \" \".join(analysis[\"functions\"] + analysis[\"classes\"]).lower()\n",
    "        for kw in business_keywords:\n",
    "            if kw in all_names:\n",
    "                analysis[\"business_hints\"].append(kw)\n",
    "        \n",
    "        analysis[\"functions\"] = list(set(analysis[\"functions\"]))[:12]\n",
    "        analysis[\"classes\"] = list(set(analysis[\"classes\"]))[:8]\n",
    "        analysis[\"api_routes\"] = list(set(analysis[\"api_routes\"]))[:10]\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _extract_solidity_info(self, content):\n",
    "        \"\"\"Extract contract information from Solidity files.\"\"\"\n",
    "        contracts = []\n",
    "        for match in re.finditer(r'contract\\s+(\\w+)(?:\\s+is\\s+([^{]+))?', content):\n",
    "            contract_name = match.group(1)\n",
    "            inherits = match.group(2).strip() if match.group(2) else \"\"\n",
    "            funcs = re.findall(r'function\\s+(\\w+)\\s*\\([^)]*\\)[^{]*(?:public|external)', content)\n",
    "            contracts.append({\"name\": contract_name, \"inherits\": inherits, \"functions\": funcs[:10]})\n",
    "        return contracts\n",
    "    \n",
    "    def _analyze_notebook(self, path, content):\n",
    "        \"\"\"Analyze Jupyter notebook content.\"\"\"\n",
    "        try:\n",
    "            nb = json.loads(content)\n",
    "            cells = nb.get(\"cells\", [])\n",
    "            code_cells = [c for c in cells if c.get(\"cell_type\") == \"code\"]\n",
    "            markdown_cells = [c for c in cells if c.get(\"cell_type\") == \"markdown\"]\n",
    "            \n",
    "            title = \"\"\n",
    "            description = []\n",
    "            for mc in markdown_cells[:3]:\n",
    "                md_content = \"\".join(mc.get(\"source\", []))\n",
    "                if md_content.startswith(\"#\") and not title:\n",
    "                    title = md_content.split(\"\\n\")[0].lstrip(\"#\").strip()\n",
    "                description.append(md_content[:200])\n",
    "            \n",
    "            imports = []\n",
    "            for cell in code_cells[:15]:\n",
    "                source = \"\".join(cell.get(\"source\", []))\n",
    "                for line in source.split(\"\\n\"):\n",
    "                    if line.strip().startswith((\"import \", \"from \")):\n",
    "                        mod = line.split()[1].split(\".\")[0]\n",
    "                        if mod not in imports:\n",
    "                            imports.append(mod)\n",
    "            \n",
    "            return {\n",
    "                \"purpose\": title or f\"Notebook: {path.split('/')[-1]}\",\n",
    "                \"description\": \" \".join(description)[:300],\n",
    "                \"functions\": [], \"classes\": [], \"api_routes\": [],\n",
    "                \"imports\": imports[:15],\n",
    "                \"notebook_info\": {\"code_cells\": len(code_cells), \"markdown_cells\": len(markdown_cells)},\n",
    "                \"business_hints\": []\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _analyze_business_functionality(self, key_files, code_analysis, details):\n",
    "        \"\"\"Infer business functionality from all gathered data.\"\"\"\n",
    "        business = {\n",
    "            \"domain\": [],\n",
    "            \"core_features\": [],\n",
    "            \"user_facing\": [],\n",
    "            \"data_operations\": [],\n",
    "            \"integrations\": [],\n",
    "            \"business_model\": [],\n",
    "            \"summary\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Analyze README for business context\n",
    "        readme = key_files.get(\"README.md\") or key_files.get(\"readme.md\") or \"\"\n",
    "        readme_lower = readme.lower()\n",
    "        \n",
    "        # Domain detection\n",
    "        domain_patterns = {\n",
    "            \"DeFi / Blockchain\": [\"defi\", \"blockchain\", \"ethereum\", \"solidity\", \"smart contract\", \"web3\", \"nft\", \"token\", \"wallet\", \"metamask\"],\n",
    "            \"E-Commerce\": [\"shop\", \"cart\", \"checkout\", \"payment\", \"product\", \"order\", \"inventory\", \"shipping\"],\n",
    "            \"AI / Machine Learning\": [\"machine learning\", \"ai \", \"neural\", \"model\", \"training\", \"prediction\", \"nlp\", \"gpt\", \"llm\", \"openai\"],\n",
    "            \"Data Analytics\": [\"analytics\", \"dashboard\", \"visualization\", \"report\", \"metrics\", \"data analysis\"],\n",
    "            \"SaaS / Web App\": [\"saas\", \"subscription\", \"user management\", \"authentication\", \"api\", \"rest\"],\n",
    "            \"DevOps / Infrastructure\": [\"deploy\", \"ci/cd\", \"docker\", \"kubernetes\", \"infrastructure\", \"automation\"],\n",
    "            \"Education / Learning\": [\"course\", \"tutorial\", \"learn\", \"education\", \"bootcamp\", \"homework\"],\n",
    "            \"Finance\": [\"finance\", \"banking\", \"trading\", \"investment\", \"portfolio\", \"stock\"],\n",
    "            \"Healthcare\": [\"health\", \"medical\", \"patient\", \"clinical\", \"diagnosis\"],\n",
    "            \"Social / Community\": [\"social\", \"community\", \"chat\", \"messaging\", \"forum\", \"profile\"]\n",
    "        }\n",
    "        \n",
    "        for domain, keywords in domain_patterns.items():\n",
    "            if any(kw in readme_lower or kw in (details.get(\"description\") or \"\").lower() for kw in keywords):\n",
    "                business[\"domain\"].append(domain)\n",
    "        \n",
    "        # Feature detection from code\n",
    "        all_functions = [f.lower() for f in code_analysis.get(\"all_functions\", [])]\n",
    "        all_classes = [c.lower() for c in code_analysis.get(\"all_classes\", [])]\n",
    "        all_routes = code_analysis.get(\"all_routes\", [])\n",
    "        contracts = code_analysis.get(\"contracts\", [])\n",
    "        \n",
    "        feature_patterns = {\n",
    "            \"User Authentication\": [\"login\", \"logout\", \"signup\", \"register\", \"auth\", \"session\", \"jwt\", \"oauth\"],\n",
    "            \"User Management\": [\"user\", \"profile\", \"account\", \"settings\", \"preferences\"],\n",
    "            \"Data CRUD Operations\": [\"create\", \"read\", \"update\", \"delete\", \"save\", \"load\", \"fetch\", \"get\", \"set\"],\n",
    "            \"API Endpoints\": [\"api\", \"endpoint\", \"route\", \"handler\", \"controller\"],\n",
    "            \"Payment Processing\": [\"payment\", \"pay\", \"charge\", \"invoice\", \"billing\", \"stripe\", \"checkout\"],\n",
    "            \"File Management\": [\"upload\", \"download\", \"file\", \"image\", \"document\", \"storage\"],\n",
    "            \"Notifications\": [\"notify\", \"notification\", \"alert\", \"email\", \"sms\", \"push\"],\n",
    "            \"Search & Filter\": [\"search\", \"filter\", \"query\", \"find\", \"sort\"],\n",
    "            \"Analytics & Reporting\": [\"analytics\", \"report\", \"stats\", \"metrics\", \"dashboard\"],\n",
    "            \"Token Operations\": [\"mint\", \"burn\", \"transfer\", \"approve\", \"stake\", \"unstake\", \"claim\"],\n",
    "            \"NFT Functionality\": [\"nft\", \"tokenuri\", \"metadata\", \"royalty\", \"marketplace\"],\n",
    "            \"DAO Governance\": [\"vote\", \"proposal\", \"governance\", \"delegate\", \"quorum\"],\n",
    "            \"DeFi Operations\": [\"swap\", \"liquidity\", \"pool\", \"yield\", \"farm\", \"lend\", \"borrow\"]\n",
    "        }\n",
    "        \n",
    "        code_text = \" \".join(all_functions + all_classes)\n",
    "        for feature, keywords in feature_patterns.items():\n",
    "            if any(kw in code_text for kw in keywords):\n",
    "                business[\"core_features\"].append(feature)\n",
    "        \n",
    "        # User-facing features from routes\n",
    "        if all_routes:\n",
    "            route_features = []\n",
    "            for route in all_routes:\n",
    "                route_lower = route.lower()\n",
    "                if \"user\" in route_lower or \"auth\" in route_lower:\n",
    "                    route_features.append(f\"User endpoint: {route}\")\n",
    "                elif \"api\" in route_lower:\n",
    "                    route_features.append(f\"API: {route}\")\n",
    "                else:\n",
    "                    route_features.append(f\"Route: {route}\")\n",
    "            business[\"user_facing\"] = route_features[:8]\n",
    "        \n",
    "        # Smart contract business logic\n",
    "        if contracts:\n",
    "            for c in contracts:\n",
    "                contract_features = []\n",
    "                funcs_lower = [f.lower() for f in c.get(\"functions\", [])]\n",
    "                if any(\"mint\" in f for f in funcs_lower):\n",
    "                    contract_features.append(\"Token/NFT minting\")\n",
    "                if any(\"transfer\" in f for f in funcs_lower):\n",
    "                    contract_features.append(\"Asset transfers\")\n",
    "                if any(\"stake\" in f or \"deposit\" in f for f in funcs_lower):\n",
    "                    contract_features.append(\"Staking/Deposits\")\n",
    "                if any(\"vote\" in f or \"propose\" in f for f in funcs_lower):\n",
    "                    contract_features.append(\"Governance\")\n",
    "                if any(\"swap\" in f or \"trade\" in f for f in funcs_lower):\n",
    "                    contract_features.append(\"Trading/Swaps\")\n",
    "                if contract_features:\n",
    "                    business[\"data_operations\"].append(f\"{c['name']}: {', '.join(contract_features)}\")\n",
    "        \n",
    "        # Integrations from dependencies\n",
    "        pkg_json = key_files.get(\"package.json\", \"\")\n",
    "        requirements = key_files.get(\"requirements.txt\", \"\")\n",
    "        deps_text = pkg_json.lower() + requirements.lower()\n",
    "        \n",
    "        integration_patterns = {\n",
    "            \"OpenAI / GPT\": [\"openai\", \"gpt-\"],\n",
    "            \"Stripe Payments\": [\"stripe\"],\n",
    "            \"AWS Services\": [\"aws-sdk\", \"boto3\", \"s3\", \"dynamodb\"],\n",
    "            \"Firebase\": [\"firebase\"],\n",
    "            \"MongoDB\": [\"mongodb\", \"mongoose\", \"pymongo\"],\n",
    "            \"PostgreSQL\": [\"pg\", \"psycopg\", \"postgres\"],\n",
    "            \"Redis\": [\"redis\", \"ioredis\"],\n",
    "            \"Ethereum/Web3\": [\"ethers\", \"web3\", \"hardhat\"],\n",
    "            \"IPFS\": [\"ipfs\", \"pinata\"],\n",
    "            \"Twilio\": [\"twilio\"],\n",
    "            \"SendGrid\": [\"sendgrid\"],\n",
    "            \"Auth0\": [\"auth0\"],\n",
    "            \"Supabase\": [\"supabase\"]\n",
    "        }\n",
    "        \n",
    "        for integration, keywords in integration_patterns.items():\n",
    "            if any(kw in deps_text for kw in keywords):\n",
    "                business[\"integrations\"].append(integration)\n",
    "        \n",
    "        # Business model hints\n",
    "        if \"subscription\" in readme_lower or \"premium\" in readme_lower:\n",
    "            business[\"business_model\"].append(\"Subscription-based\")\n",
    "        if \"marketplace\" in readme_lower or \"sell\" in readme_lower:\n",
    "            business[\"business_model\"].append(\"Marketplace\")\n",
    "        if \"open source\" in readme_lower or \"mit license\" in readme_lower:\n",
    "            business[\"business_model\"].append(\"Open Source\")\n",
    "        if \"hackathon\" in readme_lower or \"demo\" in readme_lower:\n",
    "            business[\"business_model\"].append(\"Hackathon/Demo Project\")\n",
    "        if contracts:\n",
    "            business[\"business_model\"].append(\"Blockchain/Smart Contracts\")\n",
    "        \n",
    "        # Generate summary\n",
    "        domain_str = \", \".join(business[\"domain\"][:2]) if business[\"domain\"] else \"General software\"\n",
    "        features_str = \", \".join(business[\"core_features\"][:4]) if business[\"core_features\"] else \"various features\"\n",
    "        \n",
    "        business[\"summary\"] = f\"This is a {domain_str} project that implements {features_str}.\"\n",
    "        if business[\"integrations\"]:\n",
    "            business[\"summary\"] += f\" It integrates with {', '.join(business['integrations'][:3])}.\"\n",
    "        if business[\"business_model\"]:\n",
    "            business[\"summary\"] += f\" ({', '.join(business['business_model'][:2])})\"\n",
    "        \n",
    "        return business\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print a formatted summary of the analysis.\"\"\"\n",
    "        details = self.analysis.get(\"details\", {})\n",
    "        languages = self.analysis.get(\"languages\", {})\n",
    "        tree = self.analysis.get(\"tree\", {})\n",
    "        key_files = self.analysis.get(\"key_files\", {})\n",
    "        code_analysis = self.analysis.get(\"code_analysis\", {})\n",
    "        business = self.analysis.get(\"business\", {})\n",
    "        \n",
    "        # === HEADER ===\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üì¶ REPOSITORY OVERVIEW\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Name:        {details.get('full_name', 'N/A')}\")\n",
    "        print(f\"Description: {details.get('description') or 'No description'}\")\n",
    "        print(f\"URL:         {details.get('html_url', 'N/A')}\")\n",
    "        print(f\"Created:     {details.get('created_at', '')[:10]}\")\n",
    "        print(f\"Updated:     {details.get('updated_at', '')[:10]}\")\n",
    "        print(f\"Stars:       {details.get('stargazers_count', 0)} ‚≠ê  |  Forks: {details.get('forks_count', 0)}\")\n",
    "        \n",
    "        # === BUSINESS SUMMARY (NEW) ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üíº BUSINESS FUNCTIONALITY SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if business.get(\"summary\"):\n",
    "            print(f\"\\nüìù {business['summary']}\")\n",
    "        \n",
    "        if business.get(\"domain\"):\n",
    "            print(f\"\\nüéØ Domain: {', '.join(business['domain'])}\")\n",
    "        \n",
    "        if business.get(\"core_features\"):\n",
    "            print(\"\\n‚ú® Core Business Features:\")\n",
    "            for feat in business[\"core_features\"][:8]:\n",
    "                print(f\"   ‚Ä¢ {feat}\")\n",
    "        \n",
    "        if business.get(\"user_facing\"):\n",
    "            print(\"\\nüë§ User-Facing Endpoints:\")\n",
    "            for uf in business[\"user_facing\"][:6]:\n",
    "                print(f\"   ‚Ä¢ {uf}\")\n",
    "        \n",
    "        if business.get(\"data_operations\"):\n",
    "            print(\"\\nüìä Data/Contract Operations:\")\n",
    "            for op in business[\"data_operations\"][:5]:\n",
    "                print(f\"   ‚Ä¢ {op}\")\n",
    "        \n",
    "        if business.get(\"integrations\"):\n",
    "            print(f\"\\nüîå External Integrations: {', '.join(business['integrations'])}\")\n",
    "        \n",
    "        if business.get(\"business_model\"):\n",
    "            print(f\"\\nüí∞ Business Model: {', '.join(business['business_model'])}\")\n",
    "        \n",
    "        # === TECH STACK ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üíª TECH STACK & LANGUAGES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if languages:\n",
    "            total_bytes = sum(languages.values())\n",
    "            for lang, bytes_count in sorted(languages.items(), key=lambda x: -x[1])[:6]:\n",
    "                pct = (bytes_count / total_bytes) * 100\n",
    "                bar = \"‚ñà\" * int(pct / 5) + \"‚ñë\" * (20 - int(pct / 5))\n",
    "                print(f\"{lang:<15} {bar} {pct:>5.1f}%\")\n",
    "        \n",
    "        print(\"\\nüìö Frameworks/Tools:\")\n",
    "        frameworks = self._detect_frameworks(key_files)\n",
    "        for fw in frameworks[:8]:\n",
    "            print(f\"   ‚Ä¢ {fw}\")\n",
    "        \n",
    "        # === ARCHITECTURE ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üèóÔ∏è ARCHITECTURE & STRUCTURE\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        tree_items = tree.get(\"tree\", [])\n",
    "        dirs = sorted(set(f[\"path\"].split(\"/\")[0] for f in tree_items if \"/\" in f[\"path\"]))\n",
    "        \n",
    "        file_counts = code_analysis.get(\"file_counts\", {})\n",
    "        counts_str = \", \".join([f\"{k}: {v}\" for k, v in file_counts.items() if v > 0])\n",
    "        print(f\"\\nüìä Source Files: {counts_str}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Structure ({len(dirs)} directories):\")\n",
    "        for d in dirs[:10]:\n",
    "            subfiles = len([f for f in tree_items if f[\"path\"].startswith(d + \"/\")])\n",
    "            print(f\"   üìÇ {d}/ ({subfiles} items)\")\n",
    "        \n",
    "        # === CODE FUNCTIONALITY ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"‚öôÔ∏è CODE MODULES & FUNCTIONS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        main_modules = code_analysis.get(\"main_modules\", [])\n",
    "        for mod in main_modules[:6]:\n",
    "            path = mod[\"path\"]\n",
    "            analysis = mod[\"analysis\"]\n",
    "            print(f\"\\nüìÑ {path}\")\n",
    "            if analysis.get(\"purpose\"):\n",
    "                purpose = analysis[\"purpose\"][:120]\n",
    "                print(f\"   Purpose: {purpose}{'...' if len(analysis.get('purpose', '')) > 120 else ''}\")\n",
    "            if analysis.get(\"classes\"):\n",
    "                print(f\"   Classes: {', '.join(analysis['classes'][:5])}\")\n",
    "            if analysis.get(\"functions\"):\n",
    "                print(f\"   Functions: {', '.join(analysis['functions'][:8])}\")\n",
    "            if analysis.get(\"api_routes\"):\n",
    "                print(f\"   Routes: {', '.join(analysis['api_routes'][:5])}\")\n",
    "            if analysis.get(\"notebook_info\"):\n",
    "                nb = analysis[\"notebook_info\"]\n",
    "                print(f\"   Notebook: {nb['code_cells']} code, {nb['markdown_cells']} markdown cells\")\n",
    "        \n",
    "        # Smart contracts\n",
    "        contracts = code_analysis.get(\"contracts\", [])\n",
    "        if contracts:\n",
    "            print(\"\\nüìú Smart Contracts:\")\n",
    "            for c in contracts[:4]:\n",
    "                inherits = f\" ‚Üí {c['inherits']}\" if c.get(\"inherits\") else \"\"\n",
    "                print(f\"   ‚Ä¢ {c['name']}{inherits}\")\n",
    "                if c.get(\"functions\"):\n",
    "                    print(f\"     Functions: {', '.join(c['functions'][:6])}\")\n",
    "        \n",
    "        # === README EXCERPT ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìñ PROJECT DESCRIPTION (README)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        readme = key_files.get(\"README.md\") or key_files.get(\"readme.md\") or \"\"\n",
    "        if readme:\n",
    "            lines = [l for l in readme.split(\"\\n\")[:40] \n",
    "                    if l.strip() and not l.strip().startswith((\"![\", \"<img\", \"[![\", \"---\"))][:15]\n",
    "            print(\"\\n\" + \"\\n\".join(lines))\n",
    "        else:\n",
    "            print(\"\\nNo README found\")\n",
    "        \n",
    "        # === DEPENDENCIES ===\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üì¶ KEY DEPENDENCIES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if \"package.json\" in key_files:\n",
    "            try:\n",
    "                pkg = json.loads(key_files[\"package.json\"])\n",
    "                deps = list(pkg.get(\"dependencies\", {}).keys())[:8]\n",
    "                if deps:\n",
    "                    print(f\"\\nNPM: {', '.join(deps)}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if \"requirements.txt\" in key_files:\n",
    "            deps = [l.split(\"==\")[0].split(\">=\")[0].strip() \n",
    "                   for l in key_files[\"requirements.txt\"].split(\"\\n\") \n",
    "                   if l.strip() and not l.startswith(\"#\")][:8]\n",
    "            if deps:\n",
    "                print(f\"\\nPython: {', '.join(deps)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    def _detect_frameworks(self, key_files):\n",
    "        \"\"\"Detect frameworks based on config files.\"\"\"\n",
    "        frameworks = []\n",
    "        pkg = key_files.get(\"package.json\", \"\").lower()\n",
    "        req = key_files.get(\"requirements.txt\", \"\").lower()\n",
    "        \n",
    "        checks = [\n",
    "            (pkg, \"react\", \"React\"), (pkg, \"next\", \"Next.js\"), (pkg, \"vue\", \"Vue.js\"),\n",
    "            (pkg, \"express\", \"Express.js\"), (pkg, \"hardhat\", \"Hardhat\"), (pkg, \"ethers\", \"Ethers.js\"),\n",
    "            (pkg, \"typescript\", \"TypeScript\"), (pkg, \"vite\", \"Vite\"),\n",
    "            (req, \"django\", \"Django\"), (req, \"flask\", \"Flask\"), (req, \"fastapi\", \"FastAPI\"),\n",
    "            (req, \"torch\", \"PyTorch\"), (req, \"tensorflow\", \"TensorFlow\"),\n",
    "            (req, \"langchain\", \"LangChain\"), (req, \"openai\", \"OpenAI\"),\n",
    "            (req, \"pandas\", \"Pandas\"), (req, \"numpy\", \"NumPy\")\n",
    "        ]\n",
    "        \n",
    "        for source, keyword, name in checks:\n",
    "            if keyword in source:\n",
    "                frameworks.append(name)\n",
    "        \n",
    "        if \"Dockerfile\" in key_files:\n",
    "            frameworks.append(\"Docker\")\n",
    "        \n",
    "        return list(set(frameworks)) or [\"No specific frameworks detected\"]\n",
    "\n",
    "# Run the analysis\n",
    "if github and repo_list:\n",
    "    idx = SELECTED_REPO_NUMBER - 1\n",
    "    if 0 <= idx < len(repo_list):\n",
    "        selected = repo_list[idx]\n",
    "        owner = selected[\"owner\"][\"login\"]\n",
    "        repo_name = selected[\"name\"]\n",
    "        \n",
    "        analyzer = RepoAnalyzer(github)\n",
    "        analyzer.analyze(owner, repo_name)\n",
    "        analyzer.print_summary()\n",
    "    else:\n",
    "        print(f\"‚ùå Invalid selection. Choose a number between 1 and {len(repo_list)}\")\n",
    "else:\n",
    "    print(\"‚ùå Run the previous cells first to load repos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
